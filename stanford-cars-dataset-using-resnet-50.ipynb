{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Utilizing Transfer Learning on ResNet50 to build a cars classifier using Stanford Cars Dataset \n\nFor the sake of simplicity and ease, the following notebook is run on kaggle virtual environment. The dataset used is Stanford cars dataset, which is also provided by kaggle in their list. \nURL: https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder\n\nInformation about dataset:\nThe dataset had 8144 training images and 8041 testing images, with 196 classes present in the whole dataset. On average, each class has around 40 images in both training and testing set.","metadata":{}},{"cell_type":"markdown","source":"According to https://paperswithcode.com/sota/fine-grained-image-classification-on-stanford , ResNet50 architectures give an accuracy of maximum 92.7% when trained on stanford cars dataset.","metadata":{}},{"cell_type":"markdown","source":"![image.png](attachment:00fe5fc7-f41f-42e1-9e77-df3a1bc53fb2.png)","metadata":{},"attachments":{"00fe5fc7-f41f-42e1-9e77-df3a1bc53fb2.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"Goals of this project: \n1. to build model that is able to achieve atleast 90% accuracy on test dataset\n2. to test the effects of image transformations on the model and how much it increases the accuracy.\n\nTo achieve the above goals, three sections will be presented in this notebook.  </br>\nIn the first section we build a base model without changing the images other than resizing them. </br>\nIn the second section we build the same model but we apply <b>normalization</b> to images. </br>\nand in third section we build the same model but with both <b>image transformations</b> and <b>normalization</b> applied to the base images. </br>\nFinally, the accuracies are measured and judged.\n\n<b>NOTE:</b> most of the code in the notebook has been used from the official pytorch documention on how to perform transfer learning.","metadata":{}},{"cell_type":"markdown","source":"After tuning, the following hyperparameters have shown to give optimal results.\nFor this project, the hyperparameters are kept constant so that we can compare the final results.\n\nlearning rate: 0.01</br>\nbatch size: 32</br>\nepochs: 15</br> \n\noptimizer: SGD\n\nfor transfer learning , we are using ResNet-50 and the last layer is replaced with an untrained fully connected layer of size 196\n\nThe images are resized to 400 x 400 and the normalization is done with mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]). </br>\nWhile 224 x 224 is normally used for ResNet 50 architecture, on performing a few tests that size is shown to not be enough for the model to learn well. Since pytorch allows its users to use images higher than 224 x 224, I decided to use that feature instead.\n\nWhen using image transformations, the following transformations are used </br>\n1. transforms.RandomHorizontalFlip() </br>\n2. transforms.RandomAffine(0, shear=10, scale=(0.8,1.2))</br>\n3. transforms.RandomRotation(15)</br>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport time\nimport os\nimport PIL.Image as Image\nfrom IPython.display import display\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(torch.cuda.get_device_name(device))","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:30.368008Z","iopub.execute_input":"2021-12-25T07:35:30.368290Z","iopub.status.idle":"2021-12-25T07:35:30.375493Z","shell.execute_reply.started":"2021-12-25T07:35:30.368240Z","shell.execute_reply":"2021-12-25T07:35:30.374531Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Training and evaluation functions","metadata":{}},{"cell_type":"code","source":"# Function to train model\ndef train_model(model, criterion, optimizer , n_epochs):\n    accr_list = []\n    test_accr_list = []\n    \n    # start model in train mode\n    model.train()\n    \n    # iterate through number of epochs\n    for epoch in range(n_epochs):\n        start_time = time.time()\n        \n        # to calculate loss and number of corrects\n        running_loss = 0.0\n        running_correct = 0.0\n        \n        # iterate over train data\n        for i, data in enumerate(trainloader, 0):\n\n            # get the inputs\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            \n            # forward propagation\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            # backward propagation\n            loss.backward()\n            \n            # optimize\n            optimizer.step()\n            \n            # find loss and number of corrects\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-start_time\n        \n        # find loss\n        epoch_loss = running_loss/len(trainloader)\n        \n        # find accuracy\n        epoch_acc = 100/32*running_correct/len(trainloader)\n        \n        print(\"Epoch:\", epoch+1,\" duration:\", epoch_duration, \" loss:\", epoch_loss, \" acc:\", epoch_acc)\n        \n        accr_list.append(epoch_acc)\n        \n        # switch the model to eval mode to evaluate on test data\n        model.eval()\n        test_acc = eval_model(model)\n        test_accr_list.append(test_acc)\n        \n        # change back to train mode\n        model.train()\n    print('Finished Training')\n    return model, accr_list, test_accr_list","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:31.114322Z","iopub.execute_input":"2021-12-25T07:35:31.114569Z","iopub.status.idle":"2021-12-25T07:35:31.124353Z","shell.execute_reply.started":"2021-12-25T07:35:31.114521Z","shell.execute_reply":"2021-12-25T07:35:31.123185Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# function to evaluate test data after each iteration\ndef eval_model(model):\n    \n    # iterators to count total and correct from the test images\n    correct = 0.0\n    total = 0.0\n    \n    with torch.no_grad():\n        \n        # iterate over test data\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    # calculate accuracy\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:31.669040Z","iopub.execute_input":"2021-12-25T07:35:31.669272Z","iopub.status.idle":"2021-12-25T07:35:31.674860Z","shell.execute_reply.started":"2021-12-25T07:35:31.669228Z","shell.execute_reply":"2021-12-25T07:35:31.674172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Section 1: Building a model without normalization and image transformations","metadata":{}},{"cell_type":"code","source":"directory = \"../input/car_data/car_data/\"\n\ntrain_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                 transforms.ToTensor()])\ntest_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                transforms.ToTensor()])\n\ndataset = torchvision.datasets.ImageFolder(root=directory+\"train\", transform = train_tfms)\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=directory+\"test\", transform = test_tfms)\ntestloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:37.667752Z","iopub.execute_input":"2021-12-25T07:35:37.668038Z","iopub.status.idle":"2021-12-25T07:35:38.049254Z","shell.execute_reply.started":"2021-12-25T07:35:37.667984Z","shell.execute_reply":"2021-12-25T07:35:38.048400Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# replace the last fc layer with an untrained one (requires grad by default)\nmodel_ft.fc = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:38.072649Z","iopub.execute_input":"2021-12-25T07:35:38.072898Z","iopub.status.idle":"2021-12-25T07:35:38.998944Z","shell.execute_reply.started":"2021-12-25T07:35:38.072851Z","shell.execute_reply":"2021-12-25T07:35:38.998137Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_ft, training_accs, test_accs = train_model(model_ft, criterion, optimizer, n_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T07:35:39.000469Z","iopub.execute_input":"2021-12-25T07:35:39.000993Z","iopub.status.idle":"2021-12-25T08:48:28.754200Z","shell.execute_reply.started":"2021-12-25T07:35:39.000942Z","shell.execute_reply":"2021-12-25T08:48:28.753312Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Section 2: Building a model with just image Normalization","metadata":{}},{"cell_type":"code","source":"directory = \"../input/car_data/car_data/\"\n\ntrain_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                 transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\ntest_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                transforms.ToTensor(),\n                               transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\ndataset = torchvision.datasets.ImageFolder(root=directory+\"train\", transform = train_tfms)\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=directory+\"test\", transform = test_tfms)\ntestloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-25T08:48:28.755739Z","iopub.execute_input":"2021-12-25T08:48:28.756218Z","iopub.status.idle":"2021-12-25T08:48:29.082728Z","shell.execute_reply.started":"2021-12-25T08:48:28.756158Z","shell.execute_reply":"2021-12-25T08:48:29.082037Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# replace the last fc layer with an untrained one (requires grad by default)\nmodel_ft.fc = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T08:48:29.084829Z","iopub.execute_input":"2021-12-25T08:48:29.085294Z","iopub.status.idle":"2021-12-25T08:48:29.819338Z","shell.execute_reply.started":"2021-12-25T08:48:29.085243Z","shell.execute_reply":"2021-12-25T08:48:29.818555Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model_ft, training_accs, test_accs = train_model(model_ft, criterion, optimizer, n_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T08:48:29.820656Z","iopub.execute_input":"2021-12-25T08:48:29.820900Z","iopub.status.idle":"2021-12-25T10:02:50.881001Z","shell.execute_reply.started":"2021-12-25T08:48:29.820856Z","shell.execute_reply":"2021-12-25T10:02:50.880122Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Section 3: Building a model with both normalization and image transformations","metadata":{}},{"cell_type":"code","source":"directory = \"../input/car_data/car_data/\"\n\ntrain_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                                 transforms.RandomRotation(15),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\ntest_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n\ndataset = torchvision.datasets.ImageFolder(root=directory+\"train\", transform = train_tfms)\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=directory+\"test\", transform = test_tfms)\ntestloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-25T11:18:52.891245Z","iopub.execute_input":"2021-12-25T11:18:52.891536Z","iopub.status.idle":"2021-12-25T11:18:53.239500Z","shell.execute_reply.started":"2021-12-25T11:18:52.891482Z","shell.execute_reply":"2021-12-25T11:18:53.238875Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# replace the last fc layer with an untrained one (requires grad by default)\nmodel_ft.fc = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T11:18:53.240793Z","iopub.execute_input":"2021-12-25T11:18:53.241072Z","iopub.status.idle":"2021-12-25T11:18:54.000436Z","shell.execute_reply.started":"2021-12-25T11:18:53.241027Z","shell.execute_reply":"2021-12-25T11:18:53.999651Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_ft, training_accs, test_accs = train_model(model_ft, criterion, optimizer, n_epochs=17)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T11:18:54.001719Z","iopub.execute_input":"2021-12-25T11:18:54.001996Z","iopub.status.idle":"2021-12-25T12:44:35.618105Z","shell.execute_reply.started":"2021-12-25T11:18:54.001944Z","shell.execute_reply":"2021-12-25T12:44:35.617140Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion","metadata":{}},{"cell_type":"markdown","source":"Models in both section 1 and section 2 show similar results, but model 3 has shown to give slightly different results. The value of train loss is decreasing slower than previous models per epoch. Furthermore, the accuracy on test data is slightly lower than before, however this slight decrease is not a massive problem as training for a few more epochs should let the model learn enough to achieve the same level of accuracy. \n\nThe learning is slow but steady when we use image transformations. \n\nFrom this, we can infer that the random image transformations are giving the model a regularization effect.","metadata":{}}]}